import streamlit as st
from google.generativeai.types import HarmCategory, HarmBlockThreshold
import google.generativeai as genai
import os, io, requests, time
# --- DÃ¡n Ä‘oáº¡n nÃ y ngay sau cÃ¡c dÃ²ng import á»Ÿ Ä‘áº§u file ---
from google.generativeai.types import HarmCategory, HarmBlockThreshold

safety_settings = {
    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,
    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,
    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_ONLY_HIGH,
    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,
}
# --------------------------------------------------------
from PIL import Image
from PyPDF2 import PdfReader
from docx import Document
from bs4 import BeautifulSoup

# --- Cáº¤U HÃŒNH ---
st.set_page_config(page_title="SiÃªu AI Äa NÄƒng", page_icon="ğŸš€", layout="wide")
st.markdown("""<style>.stButton>button {background-color: #d35400; color: white;}</style>""", unsafe_allow_html=True)

# --- Káº¾T Ná»I API ---
try:
    api_key = st.secrets["GEMINI_API_KEY"]
    genai.configure(api_key=api_key)
    
    # Tá»± Ä‘á»™ng láº¥y danh sÃ¡ch Model
    available_models = []
    try:
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods and 'gemini' in m.name:
                available_models.append(m.name)
    except: pass
    if not available_models: 
        available_models = ["models/gemini-1.5-pro", "models/gemini-1.5-flash"]
except:
    st.error("âš ï¸ ChÆ°a nháº­p API Key trong Secrets.")
    st.stop()

# --- HÃ€M Xá»¬ LÃ FILE ---
def get_text_from_files(files):
    text = ""
    for f in files:
        if f.name.endswith('.pdf'):
            reader = PdfReader(f)
            for page in reader.pages: text += page.extract_text() or ""
        elif f.name.endswith('.docx'):
            doc = Document(f)
            for para in doc.paragraphs: text += para.text + "\n"
        elif f.name.endswith('.txt'):
            text += f.getvalue().decode("utf-8")
    return text

def save_docx(content):
    doc = Document()
    for line in content.split('\n'):
        if line.strip(): doc.add_paragraph(line)
    bio = io.BytesIO()
    doc.save(bio)
    return bio

def scrape_url(url):
    try:
        res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=10)
        soup = BeautifulSoup(res.content, 'html.parser')
        return "\n".join([p.get_text() for p in soup.find_all('p')])
    except: return ""

# --- GIAO DIá»†N ---
st.title("ğŸš€ SiÃªu Trá»£ LÃ½: Huyá»n Há»c - Marketing - Dá»‹ch Thuáº­t")

with st.sidebar:
    st.header("âš™ï¸ Cáº¤U HÃŒNH")
    selected_model = st.selectbox("Chá»n Model:", available_models)
    st.divider()
    menu = st.radio("CHá»¨C NÄ‚NG:", ["ğŸ”® Há»i ÄÃ¡p ChuyÃªn SÃ¢u (Huyá»n há»c/Data)", "ğŸ­ Dá»‹ch Thuáº­t CÃ´ng Nghiá»‡p", "ğŸ–¼ï¸ Dá»‹ch áº¢nh (OCR)"])

model = genai.GenerativeModel(selected_model)

# --- 1. Há»I ÄÃP CHUYÃŠN SÃ‚U ---
if menu == "ğŸ”® Há»i ÄÃ¡p ChuyÃªn SÃ¢u (Huyá»n há»c/Data)":
    st.subheader("ğŸ”® Trá»£ LÃ½ ChuyÃªn Gia (Náº¡p sÃ¡ch/Dá»¯ liá»‡u)")
    
    with st.sidebar:
        role = st.selectbox("Vai trÃ² AI:", ["Äáº¡i sÆ° Huyá»n há»c (Giang CÃ´ng)", "ChuyÃªn gia Marketing & Data", "Trá»£ lÃ½ Ä‘a nÄƒng"])
        files = st.file_uploader("Náº¡p tÃ i liá»‡u (PDF/Docx):", accept_multiple_files=True)
        if st.button("Náº¡p vÃ o bá»™ nÃ£o"):
            st.session_state.context = get_text_from_files(files)
            st.success("ÄÃ£ náº¡p xong tÃ i liá»‡u!")

    if "context" not in st.session_state: st.session_state.context = ""
    if "chat_history" not in st.session_state: st.session_state.chat_history = []

    for m in st.session_state.chat_history:
        st.chat_message(m["role"]).markdown(m["content"])

    if q := st.chat_input("Há»i AI..."):
        st.session_state.chat_history.append({"role": "user", "content": q})
        st.chat_message("user").markdown(q)
        
        prompt = f"VAI TRÃ’: {role}\nKIáº¾N THá»¨C Bá»” TRá»¢: {st.session_state.context}\nCÃ‚U Há»I: {q}"
        
        with st.spinner("AI Ä‘ang suy nghÄ©..."):
            try:
                res = model.generate_content(prompt, safety_settings=safety_settings)
                st.chat_message("assistant").markdown(res.text)
                st.session_state.chat_history.append({"role": "assistant", "content": res.text})
            except Exception as e: st.error(f"Lá»—i: {e}")

# --- 2. Dá»ŠCH THUáº¬T CÃ”NG NGHIá»†P ---
elif menu == "ğŸ­ Dá»‹ch Thuáº­t CÃ´ng Nghiá»‡p":
    st.subheader("ğŸ­ Dá»‹ch SÃ¡ch & Truyá»‡n HÃ ng Loáº¡t")
    instr = st.text_area("YÃªu cáº§u dá»‹ch (VÄƒn phong, xÆ°ng hÃ´...):", value="Dá»‹ch sang tiáº¿ng Viá»‡t mÆ°á»£t mÃ , dá»… hiá»ƒu.")
    gloss = st.text_area("Tá»« Ä‘iá»ƒn thuáº­t ngá»¯:", value="TrÃºc CÆ¡, ROI")
    
    tab1, tab2 = st.tabs(["ğŸ“„ Dá»‹ch File", "ğŸŒ Dá»‹ch Link Web"])
    
    with tab1:
        up_files = st.file_uploader("Táº£i nhiá»u file:", accept_multiple_files=True)
        if st.button("Báº¯t Ä‘áº§u dá»‹ch File"):
            for f in up_files:
                txt = get_text_from_files([f])
                chunks = [txt[i:i+5000] for i in range(0, len(txt), 5000)]
                full_trans = ""
                p_bar = st.progress(0)
                for i, c in enumerate(chunks):
                   # --- Báº®T Äáº¦U ÄOáº N CODE Tá»° Äá»˜NG THá»¬ Láº I ---
import time

# Thá»­ tá»‘i Ä‘a 3 láº§n náº¿u bá»‹ lá»—i
for attempt in range(3):
    try:
        # Cá»‘ gáº¯ng gá»i AI
        res = model.generate_content(f"YÃŠU Cáº¦U: {instr}\nTHUáº¬T NGá»®: {gloss}\nDá»ŠCH ÄOáº N NÃ€Y: {c}", safety_settings=safety_settings)
        break # Náº¿u thÃ nh cÃ´ng (khÃ´ng lá»—i) thÃ¬ thoÃ¡t vÃ²ng láº·p ngay
    except Exception as e:
        # Náº¿u gáº·p lá»—i (báº¥t ká»ƒ lá»—i gÃ¬)
        if "ResourceExhausted" in str(e):
            # Náº¿u lÃ  lá»—i quÃ¡ táº£i, nghá»‰ 20 giÃ¢y rá»“i thá»­ láº¡i
            time.sleep(20) 
        else:
            # Náº¿u lÃ  lá»—i khÃ¡c thÃ¬ bá» qua luÃ´n
            break
# --- Káº¾T THÃšC ÄOáº N CODE ---
                    full_trans += res.text + "\n\n"
                    p_bar.progress((i+1)/len(chunks))
                st.download_button(f"Táº£i báº£n dá»‹ch {f.name}", save_docx(full_trans).getvalue(), f"VN_{f.name}.docx")

    with tab2:
        urls = st.text_area("DÃ¡n danh sÃ¡ch Link (má»—i dÃ²ng 1 link):")
        if st.button("Báº¯t Ä‘áº§u dá»‹ch Link"):
            links = urls.split("\n")
            all_txt = ""
            for l in links:
                if l.strip():
                    raw = scrape_url(l.strip())
                    res = model.generate_content(f"Dá»‹ch ná»™i dung sau: {raw[:15000]}", safety_settings=safety_settings)
                    all_txt += f"\n--- {l} ---\n" + res.text
            st.download_button("Táº£i file dá»‹ch tá»•ng há»£p", save_docx(all_txt).getvalue(), "Dich_Web.docx")

# --- 3. Dá»ŠCH áº¢NH ---
elif menu == "ğŸ–¼ï¸ Dá»‹ch áº¢nh (OCR)":
    st.subheader("ğŸ–¼ï¸ Dá»‹ch chá»¯ tá»« HÃ¬nh áº£nh")
    imgs = st.file_uploader("Táº£i áº£nh lÃªn:", accept_multiple_files=True, type=['png', 'jpg', 'jpeg'])
    if imgs and st.button("Báº¯t Ä‘áº§u dá»‹ch áº£nh"):
        full_ocr = ""
        for im_f in imgs:
            img = Image.open(im_f)
            st.image(img, width=300)
            res = model.generate_content(["Nháº­n diá»‡n chá»¯ trong áº£nh (ká»ƒ cáº£ tiáº¿ng Trung dá»c) vÃ  dá»‹ch sang Tiáº¿ng Viá»‡t:", img], safety_settings=safety_settings)
            full_ocr += f"\n--- {im_f.name} ---\n" + res.text
        st.text_area("Káº¿t quáº£:", full_ocr, height=300)
        st.download_button("Táº£i file dá»‹ch áº£nh (.docx)", save_docx(full_ocr).getvalue(), "Dich_Anh.docx")
